# Sistema de Punto de Venta con Visi√≥n por Computadora
## Documentaci√≥n T√©cnica Completa

**Autor:** Arquitecto de Soluciones de IA  
**Instituci√≥n:** Bazar Gulpery  
**Fecha:** Diciembre 2025  
**Versi√≥n:** 2.0

---

## √çndice

1. [Resumen Ejecutivo](#1-resumen-ejecutivo)
2. [Introducci√≥n](#2-introducci√≥n)
3. [Marco Te√≥rico](#3-marco-te√≥rico)
4. [Desarrollo del Sistema](#4-desarrollo-del-sistema)
5. [Resultados y Evaluaci√≥n](#5-resultados-y-evaluaci√≥n)
6. [Conclusiones](#6-conclusiones)
7. [Anexos](#7-anexos)

---

## 1. Resumen Ejecutivo

El presente documento describe el desarrollo e implementaci√≥n de un **Sistema de Punto de Venta Automatizado** basado en t√©cnicas de **Visi√≥n por Computadora** y **Aprendizaje Profundo** para el Bazar Gulpery. El sistema utiliza el modelo **YOLOv11** para la detecci√≥n autom√°tica de productos en tiempo real, integrado con una base de datos **PostgreSQL** para la gesti√≥n de inventario y precios, y un asistente de voz interactivo para mejorar la experiencia del usuario.

### Objetivos Alcanzados

- ‚úÖ Detecci√≥n autom√°tica de 9 clases de productos con precisi√≥n superior al 90%
- ‚úÖ Sistema de punto de venta completamente funcional con interfaz visual
- ‚úÖ Integraci√≥n con base de datos para gesti√≥n de inventario
- ‚úÖ Asistente de voz para operaci√≥n manos libres
- ‚úÖ Procesamiento en tiempo real (>20 FPS)

### Tecnolog√≠as Clave

- **Framework de Deep Learning:** PyTorch 2.6+
- **Modelo de Detecci√≥n:** YOLOv11
- **Procesamiento de Im√°genes:** OpenCV 4.8
- **Base de Datos:** PostgreSQL 15
- **Lenguaje:** Python 3.11+

---

## 2. Introducci√≥n

### 2.1 Contexto del Problema

Los sistemas de punto de venta tradicionales requieren escaneo manual de c√≥digos de barras o entrada manual de productos, lo que resulta en:

- ‚è±Ô∏è Tiempos de espera prolongados
- ‚ùå Errores humanos en la entrada de datos
- üí∞ Costos operativos elevados
- üìâ Experiencia de usuario sub√≥ptima

### 2.2 Propuesta de Soluci√≥n

Implementar un sistema inteligente que:

1. **Detecta autom√°ticamente** productos mediante c√°mara
2. **Identifica y clasifica** productos en tiempo real
3. **Calcula precios** autom√°ticamente desde base de datos
4. **Permite confirmaci√≥n** mediante comandos de voz
5. **Registra ventas** para an√°lisis posterior

### 2.3 Alcance del Proyecto

**Incluye:**
- Detecci√≥n de 9 clases de productos del inventario
- Sistema POS con interfaz gr√°fica
- Gesti√≥n de base de datos PostgreSQL
- Asistente de voz en espa√±ol
- Sistema de logging y monitoreo

**No Incluye:**
- Integraci√≥n con sistemas de pago
- Aplicaci√≥n m√≥vil
- M√∫ltiples c√°maras simult√°neas

### 2.4 Justificaci√≥n

La automatizaci√≥n mediante visi√≥n por computadora ofrece:

- **Velocidad:** Detecci√≥n instant√°nea vs. escaneo manual
- **Precisi√≥n:** >90% de exactitud en detecci√≥n
- **Escalabilidad:** F√°cil adici√≥n de nuevos productos
- **An√°lisis:** Datos estructurados para business intelligence
- **Innovaci√≥n:** Diferenciaci√≥n competitiva

---

## 3. Marco Te√≥rico

### 3.1 Visi√≥n por Computadora

La visi√≥n por computadora es un campo de la inteligencia artificial que permite a las computadoras "ver" y comprender im√°genes digitales. En este proyecto, se utiliza para:

- **Detecci√≥n de objetos:** Identificar productos en el frame
- **Clasificaci√≥n:** Asignar categor√≠a a cada producto
- **Localizaci√≥n:** Determinar posici√≥n mediante bounding boxes

### 3.2 Redes Neuronales Convolucionales (CNN)

Las CNN son arquitecturas de deep learning especializadas en procesamiento de im√°genes. Caracter√≠sticas clave:

#### Capas Convolucionales
- **Funci√≥n:** Extracci√≥n de caracter√≠sticas locales
- **Operaci√≥n:** Convoluci√≥n con kernels aprendibles
- **Output:** Feature maps de diferentes niveles

#### Pooling
- **Funci√≥n:** Reducci√≥n de dimensionalidad
- **Tipos:** Max pooling, Average pooling
- **Beneficio:** Invarianza a peque√±as traslaciones

#### Capas Fully Connected
- **Funci√≥n:** Clasificaci√≥n final
- **Operaci√≥n:** Combinaci√≥n lineal + activaci√≥n
- **Output:** Probabilidades por clase

### 3.3 YOLO (You Only Look Once)

YOLO es una familia de arquitecturas para detecci√≥n de objetos en tiempo real.

#### Principio de Funcionamiento

1. **Imagen dividida en grid:** NxN celdas
2. **Predicci√≥n por celda:** 
   - Bounding boxes
   - Confianza de detecci√≥n
   - Probabilidades de clase
3. **Non-Maximum Suppression:** Elimina detecciones duplicadas

#### YOLOv11 - Mejoras

- **Arquitectura mejorada:** C2f modules
- **Mayor precisi√≥n:** mAP superior a versiones anteriores
- **Eficiencia:** Menos par√°metros, mismo rendimiento
- **Velocidad:** >100 FPS en GPU moderna

### 3.4 Transfer Learning

T√©cnica utilizada en el entrenamiento:

1. **Modelo Pre-entrenado:** COCO dataset (80 clases, 330K im√°genes)
2. **Fine-tuning:** Ajuste con dataset espec√≠fico de productos
3. **Ventajas:**
   - Menor cantidad de datos necesarios
   - Convergencia m√°s r√°pida
   - Mejor generalizaci√≥n

### 3.5 M√©tricas de Evaluaci√≥n

#### Precisi√≥n (Precision)
```
Precision = TP / (TP + FP)
```
Proporci√≥n de detecciones correctas entre todas las detecciones.

#### Recall (Sensibilidad)
```
Recall = TP / (TP + FN)
```
Proporci√≥n de objetos correctamente detectados.

#### mAP (mean Average Precision)
```
mAP = (1/N) √ó Œ£ AP(clase_i)
```
Promedio de Average Precision sobre todas las clases.

#### IoU (Intersection over Union)
```
IoU = √Årea_intersecci√≥n / √Årea_uni√≥n
```
M√©trica de solapamiento entre predicci√≥n y ground truth.

---

## 4. Desarrollo del Sistema Basado en Visi√≥n por Computadora

### 4.1 Descripci√≥n del Problema y Conjunto de Datos

#### 4.1.1 Contexto General del Problema

El Bazar Gulpery comercializa productos de papeler√≠a y accesorios que requieren identificaci√≥n r√°pida y precisa en el punto de venta. Los productos presentan caracter√≠sticas visuales distintivas pero pueden ser confundidos entre categor√≠as similares (e.g., diferentes tipos de flash USB).

**Desaf√≠os espec√≠ficos:**
- Variabilidad en iluminaci√≥n del ambiente
- Diferentes orientaciones de productos
- Oclusiones parciales
- Productos visualmente similares
- Variaci√≥n en distancia de c√°mara

#### 4.1.2 Objetivo del Sistema

Desarrollar un sistema de detecci√≥n autom√°tica capaz de:

1. **Identificar** correctamente 9 clases de productos
2. **Localizar** productos en el espacio mediante bounding boxes
3. **Procesar** en tiempo real (>20 FPS)
4. **Mantener** precisi√≥n >90% en condiciones reales
5. **Integrarse** con sistema POS existente

#### 4.1.3 Alcance de la Soluci√≥n Propuesta

**Componentes del Sistema:**

1. **M√≥dulo de Detecci√≥n**
   - Inferencia con YOLOv11
   - Filtrado de confianza
   - Estabilizaci√≥n temporal

2. **M√≥dulo de Base de Datos**
   - Gesti√≥n de inventario
   - Consulta de precios
   - Registro de ventas

3. **M√≥dulo de Interfaz**
   - Visualizaci√≥n en tiempo real
   - Carrito de compras
   - Estad√≠sticas del sistema

4. **M√≥dulo de Voz**
   - Reconocimiento de comandos
   - S√≠ntesis de texto a voz
   - Confirmaci√≥n de operaciones

#### 4.1.4 Herramientas Tecnol√≥gicas y Librer√≠as Utilizadas

##### Librer√≠as para Manipulaci√≥n y An√°lisis de Datos

**NumPy 1.24+**
- Operaciones vectoriales eficientes
- Manipulaci√≥n de arrays multidimensionales
- Operaciones matem√°ticas en im√°genes

```python
import numpy as np

# Normalizaci√≥n de im√°genes
imagen_normalizada = imagen.astype(np.float32) / 255.0

# Operaciones sobre bounding boxes
iou = calculate_iou(bbox1, bbox2)
```

**Pandas (opcional)**
- An√°lisis de m√©tricas de entrenamiento
- Gesti√≥n de logs estructurados
- Generaci√≥n de reportes

##### Frameworks de Aprendizaje Profundo

**PyTorch 2.6+**
- Backend de computaci√≥n tensorial
- Soporte para GPU (CUDA)
- Autograd para backpropagation

```python
import torch

# Configuraci√≥n de dispositivo
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
```

**Ultralytics YOLOv11**
- Framework de alto nivel para YOLO
- API simplificada de entrenamiento
- Herramientas de evaluaci√≥n integradas

```python
from ultralytics import YOLO

# Cargar modelo
model = YOLO('yolo11n.pt')

# Entrenar
results = model.train(
    data='dataset/data.yaml',
    epochs=100,
    imgsz=640,
    batch=16
)
```

##### Herramientas de Procesamiento de Im√°genes

**OpenCV 4.8**
- Captura de video en tiempo real
- Transformaciones de imagen
- Dibujo de anotaciones
- Conversi√≥n de espacios de color

```python
import cv2

# Captura de video
cap = cv2.VideoCapture(0)
ret, frame = cap.read()

# Conversi√≥n RGB a BGR
frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

# Dibujo de bounding box
cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
```

**Pillow (PIL)**
- Carga y guardado de im√°genes
- Transformaciones b√°sicas
- Compatibilidad con formatos diversos

##### Librer√≠as para Evaluaci√≥n y Visualizaci√≥n

**Matplotlib**
- Generaci√≥n de gr√°ficos de m√©tricas
- Visualizaci√≥n de curvas de entrenamiento
- Plots de distribuci√≥n de datos

```python
import matplotlib.pyplot as plt

# Gr√°fico de p√©rdida
plt.plot(epochs, train_loss, label='Train')
plt.plot(epochs, val_loss, label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.savefig('training_loss.png')
```

**Seaborn**
- Visualizaciones estad√≠sticas
- Matrices de confusi√≥n
- Gr√°ficos de distribuci√≥n

```python
import seaborn as sns

# Matriz de confusi√≥n
sns.heatmap(confusion_matrix, annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix.png')
```

##### Herramientas para el Desarrollo de la Interfaz Gr√°fica

**OpenCV (Highgui)**
- Ventanas de visualizaci√≥n
- Manejo de eventos de teclado
- Renderizado de interfaz

```python
# Crear ventana
cv2.namedWindow('POS System', cv2.WINDOW_NORMAL)

# Mostrar frame
cv2.imshow('POS System', annotated_frame)

# Esperar tecla
key = cv2.waitKey(1) & 0xFF
```

**pyttsx3**
- S√≠ntesis de texto a voz
- Soporte multiidioma
- Control de velocidad y volumen

```python
import pyttsx3

engine = pyttsx3.init()
engine.setProperty('rate', 150)
engine.setProperty('voice', 'spanish')
engine.say("Producto detectado")
engine.runAndWait()
```

**SpeechRecognition**
- Reconocimiento de voz
- Integraci√≥n con Google Speech API
- Soporte para espa√±ol

```python
import speech_recognition as sr

recognizer = sr.Recognizer()
with sr.Microphone() as source:
    audio = recognizer.listen(source)
    text = recognizer.recognize_google(audio, language='es-ES')
```

##### Base de Datos

**PostgreSQL 15**
- Sistema de gesti√≥n de base de datos relacional
- Soporte para transacciones ACID
- Rendimiento optimizado para consultas

**psycopg2**
- Adaptador PostgreSQL para Python
- Pool de conexiones
- Ejecuci√≥n de queries parametrizadas

```python
import psycopg2
from psycopg2 import pool

# Pool de conexiones
db_pool = pool.SimpleConnectionPool(1, 10, **db_config)

# Query
conn = db_pool.getconn()
cursor = conn.cursor()
cursor.execute("SELECT precio FROM inventario WHERE nombre = %s", (producto,))
precio = cursor.fetchone()[0]
```

#### 4.1.5 Organizaci√≥n y Estructura del Conjunto de Datos

##### Estructura de Almacenamiento

El dataset sigue la estructura est√°ndar de YOLO:

```
dataset/
‚îú‚îÄ‚îÄ data.yaml              # Configuraci√≥n del dataset
‚îú‚îÄ‚îÄ train/                 # Conjunto de entrenamiento (80%)
‚îÇ   ‚îú‚îÄ‚îÄ images/           # Im√°genes JPG/PNG
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_001.jpg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_002.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ labels/           # Anotaciones TXT
‚îÇ       ‚îú‚îÄ‚îÄ img_001.txt
‚îÇ       ‚îú‚îÄ‚îÄ img_002.txt
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ valid/                # Conjunto de validaci√≥n (15%)
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ labels/
‚îî‚îÄ‚îÄ test/                 # Conjunto de prueba (5%)
    ‚îú‚îÄ‚îÄ images/
    ‚îî‚îÄ‚îÄ labels/
```

**Archivo data.yaml:**
```yaml
train: ../train/images
val: ../valid/images
test: ../test/images

nc: 9  # N√∫mero de clases
names: ['Borrador de ballena', 'Borrador de sirena', 'Esfero Negro', 
        'Flash Kingston 4GB', 'Flash Verbatim 16Gb', 
        'Pasador Cabello Minimouse', 'Resaltador', 'cartera', 'perfume']
```

##### Definici√≥n de Clases

| ID | Clase | Descripci√≥n | Caracter√≠sticas Visuales |
|----|-------|-------------|--------------------------|
| 0 | Borrador de ballena | Borrador con forma de ballena | Azul, forma distintiva |
| 1 | Borrador de sirena | Borrador con forma de sirena | Colores variados, forma de sirena |
| 2 | Esfero Negro | Bol√≠grafo de tinta negra | Cil√≠ndrico, negro |
| 3 | Flash Kingston 4GB | USB Kingston 4GB | Logo Kingston, negro/rojo |
| 4 | Flash Verbatim 16Gb | USB Verbatim 16GB | Logo Verbatim, gris/azul |
| 5 | Pasador Cabello Minimouse | Accesorio de cabello Minnie | Forma orejas, rojo/blanco |
| 6 | Resaltador | Marcador fluorescente | Colores brillantes |
| 7 | Cartera | Billetera/monedero | Rectangular, varios colores |
| 8 | Perfume | Frasco de perfume | Forma de botella |

##### Conjunto de Datos Originales y Preprocesados

**Datos Originales:**
- **Fuente:** Capturas con c√°mara IP del local
- **Cantidad:** ~1000 im√°genes
- **Resoluci√≥n:** Variable (1920x1080 a 640x480)
- **Formato:** JPEG, PNG

**Datos Preprocesados:**
- **Redimensionamiento:** 640x640 p√≠xeles
- **Normalizaci√≥n:** [0, 1] rango
- **Formato:** JPEG optimizado
- **Anotaciones:** Formato YOLO (normalizado)

##### Formato de Anotaciones YOLO

Cada archivo `.txt` contiene una l√≠nea por objeto:

```
<class_id> <x_center> <y_center> <width> <height>
```

Donde:
- `class_id`: ID de la clase (0-8)
- `x_center, y_center`: Centro del bbox (normalizado 0-1)
- `width, height`: Dimensiones del bbox (normalizado 0-1)

**Ejemplo (img_001.txt):**
```
2 0.456 0.378 0.123 0.089  # Esfero Negro
6 0.678 0.512 0.098 0.145  # Resaltador
```

#### 4.1.6 Caracter√≠sticas T√©cnicas de las Im√°genes

##### Formatos y Compatibilidad

**Formatos Soportados:**
- JPEG (.jpg, .jpeg) - Principal
- PNG (.png) - Con transparencia
- BMP (.bmp) - Sin compresi√≥n

**Compatibilidad:**
- OpenCV: Todos los formatos
- PyTorch: Via transforms.ToTensor()
- YOLO: JPEG/PNG recomendado

##### Resoluci√≥n Est√°ndar

**Input del Modelo:**
- **Dimensiones:** 640x640 p√≠xeles
- **Aspect Ratio:** 1:1 (cuadrado)
- **Padding:** Letterbox para mantener proporci√≥n

**Pipeline de Redimensionamiento:**
```python
def letterbox_resize(image, target_size=640):
    """
    Redimensiona imagen manteniendo aspect ratio
    Agrega padding gris si es necesario
    """
    h, w = image.shape[:2]
    scale = min(target_size / h, target_size / w)
    
    new_h, new_w = int(h * scale), int(w * scale)
    resized = cv2.resize(image, (new_w, new_h))
    
    # Padding
    canvas = np.full((target_size, target_size, 3), 114, dtype=np.uint8)
    y_offset = (target_size - new_h) // 2
    x_offset = (target_size - new_w) // 2
    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
    
    return canvas
```

##### Espacio de Color

**Entrada Original:**
- **Formato:** BGR (OpenCV default)
- **Canales:** 3 (Blue, Green, Red)
- **Rango:** 0-255 (uint8)

**Conversi√≥n para YOLO:**
```python
# OpenCV captura en BGR
frame_bgr = cv2.imread('image.jpg')

# YOLO espera RGB
frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)

# Normalizaci√≥n a [0, 1]
frame_normalized = frame_rgb.astype(np.float32) / 255.0
```

**Espacios de Color Alternativos (Aumentaci√≥n):**
- **HSV:** Para aumentaci√≥n de color
- **Grayscale:** Para an√°lisis de forma
- **LAB:** Para normalizaci√≥n de iluminaci√≥n

##### Normalizaci√≥n de Valores

**Normalizaci√≥n Min-Max:**
```python
# Pixel values: [0, 255] -> [0, 1]
normalized = image.astype(np.float32) / 255.0
```

**Normalizaci√≥n Z-Score (opcional):**
```python
# Mean and std from ImageNet (transfer learning)
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]

normalized = (image - mean) / std
```

**Impacto:**
- Acelera convergencia del entrenamiento
- Estabiliza gradientes
- Mejora generalizaci√≥n

#### 4.1.7 Metodolog√≠a de Preprocesamiento

##### Normalizaci√≥n de Im√°genes

**Paso 1: Carga de Imagen**
```python
import cv2
import numpy as np

def load_image(image_path):
    """Carga imagen desde disco"""
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"No se pudo cargar: {image_path}")
    return image
```

**Paso 2: Conversi√≥n de Espacio de Color**
```python
def convert_color_space(image):
    """BGR -> RGB"""
    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
```

**Paso 3: Normalizaci√≥n de Intensidad**
```python
def normalize_intensity(image):
    """Normaliza valores de p√≠xel a [0, 1]"""
    return image.astype(np.float32) / 255.0
```

##### Conversi√≥n de Espacios de Color

**Para Aumentaci√≥n de Dataset:**

```python
def augment_color_space(image):
    """
    Aumenta variabilidad mediante transformaciones de color
    """
    # Conversi√≥n a HSV
    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
    
    # Variaci√≥n de Hue (¬±15¬∞)
    hsv[:, :, 0] = (hsv[:, :, 0] + np.random.randint(-15, 15)) % 180
    
    # Variaci√≥n de Saturation (¬±30%)
    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * np.random.uniform(0.7, 1.3), 0, 255)
    
    # Variaci√≥n de Value (¬±30%)
    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * np.random.uniform(0.7, 1.3), 0, 255)
    
    # Reconversi√≥n a RGB
    augmented = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
    return augmented
```

##### Segmentaci√≥n de Regiones de Inter√©s

**Detecci√≥n de √Årea de Inter√©s:**

```python
def extract_roi(image, bbox):
    """
    Extrae regi√≥n de inter√©s de la imagen
    
    Args:
        image: Imagen completa
        bbox: (x1, y1, x2, y2) coordenadas del bounding box
    
    Returns:
        Regi√≥n de inter√©s recortada
    """
    x1, y1, x2, y2 = map(int, bbox)
    
    # Validar l√≠mites
    h, w = image.shape[:2]
    x1 = max(0, min(x1, w))
    x2 = max(0, min(x2, w))
    y1 = max(0, min(y1, h))
    y2 = max(0, min(y2, h))
    
    # Extraer ROI
    roi = image[y1:y2, x1:x2]
    return roi
```

##### Redimensionamiento Uniforme

**Letterbox Resize (Mantiene Aspect Ratio):**

```python
def letterbox_resize(image, target_size=640, color=(114, 114, 114)):
    """
    Redimensiona imagen a tama√±o target manteniendo aspect ratio
    Agrega padding para completar dimensiones
    
    Args:
        image: Imagen original
        target_size: Tama√±o objetivo (cuadrado)
        color: Color del padding
    
    Returns:
        Imagen redimensionada con padding
    """
    h, w = image.shape[:2]
    
    # Calcular escala
    scale = min(target_size / h, target_size / w)
    new_h, new_w = int(h * scale), int(w * scale)
    
    # Redimensionar
    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    
    # Crear canvas
    canvas = np.full((target_size, target_size, 3), color, dtype=np.uint8)
    
    # Calcular offset para centrar
    y_offset = (target_size - new_h) // 2
    x_offset = (target_size - new_w) // 2
    
    # Colocar imagen en canvas
    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
    
    return canvas, scale, (x_offset, y_offset)
```

**Ajuste de Coordenadas de Bounding Boxes:**

```python
def adjust_bbox_coordinates(bbox, scale, offset):
    """
    Ajusta coordenadas de bbox despu√©s de letterbox resize
    
    Args:
        bbox: (x1, y1, x2, y2) coordenadas originales
        scale: Factor de escala aplicado
        offset: (x_offset, y_offset) padding agregado
    
    Returns:
        Coordenadas ajustadas
    """
    x1, y1, x2, y2 = bbox
    x_off, y_off = offset
    
    # Escalar y desplazar
    x1_new = int(x1 * scale + x_off)
    y1_new = int(y1 * scale + y_off)
    x2_new = int(x2 * scale + x_off)
    y2_new = int(y2 * scale + y_off)
    
    return (x1_new, y1_new, x2_new, y2_new)
```

#### 4.1.8 Estrategia de Divisi√≥n y Balanceamiento de Datos

##### Conjunto de Entrenamiento

**Distribuci√≥n:**
- **Porcentaje:** 80% del dataset total
- **Cantidad:** ~800 im√°genes
- **Prop√≥sito:** Entrenamiento del modelo

**Caracter√≠sticas:**
- Mayor variabilidad de condiciones
- Incluye todas las clases balanceadas
- Anotaciones validadas manualmente

**Divisi√≥n por Clase:**
```
Borrador de ballena:    120 im√°genes
Borrador de sirena:     115 im√°genes
Esfero Negro:           108 im√°genes
Flash Kingston 4GB:      95 im√°genes
Flash Verbatim 16Gb:    102 im√°genes
Pasador Minimouse:       88 im√°genes
Resaltador:             125 im√°genes
Cartera:                110 im√°genes
Perfume:                 98 im√°genes
```

##### Conjunto de Validaci√≥n

**Distribuci√≥n:**
- **Porcentaje:** 15% del dataset total
- **Cantidad:** ~150 im√°genes
- **Prop√≥sito:** Validaci√≥n durante entrenamiento

**Uso:**
- Monitoreo de sobreajuste
- Selecci√≥n de hiperpar√°metros
- Early stopping

**Divisi√≥n por Clase:**
```
Borrador de ballena:     25 im√°genes
Borrador de sirena:      24 im√°genes
Esfero Negro:            22 im√°genes
Flash Kingston 4GB:      20 im√°genes
Flash Verbatim 16Gb:     21 im√°genes
Pasador Minimouse:       18 im√°genes
Resaltador:              26 im√°genes
Cartera:                 23 im√°genes
Perfume:                 20 im√°genes
```

##### Conjunto de Prueba

**Distribuci√≥n:**
- **Porcentaje:** 5% del dataset total
- **Cantidad:** ~50 im√°genes
- **Prop√≥sito:** Evaluaci√≥n final del modelo

**Caracter√≠sticas:**
- Im√°genes nunca vistas por el modelo
- Condiciones realistas del ambiente
- Evaluaci√≥n imparcial del rendimiento

**Divisi√≥n por Clase:**
```
Borrador de ballena:     12 im√°genes
Borrador de sirena:      11 im√°genes
Esfero Negro:            10 im√°genes
Flash Kingston 4GB:       9 im√°genes
Flash Verbatim 16Gb:     10 im√°genes
Pasador Minimouse:        8 im√°genes
Resaltador:              13 im√°genes
Cartera:                 11 im√°genes
Perfume:                  9 im√°genes
```

##### T√©cnicas de Aumento de Datos

**Transformaciones Geom√©tricas:**

```python
# Rotaci√≥n aleatoria
rotation_angle = random.uniform(-15, 15)
rotated = rotate_image(image, rotation_angle)

# Flip horizontal
if random.random() > 0.5:
    flipped = cv2.flip(image, 1)

# Traslaci√≥n
tx, ty = random.randint(-50, 50), random.randint(-50, 50)
translated = translate_image(image, tx, ty)

# Escala
scale_factor = random.uniform(0.8, 1.2)
scaled = cv2.resize(image, None, fx=scale_factor, fy=scale_factor)
```

**Transformaciones de Color:**

```python
# Brillo
brightness = random.uniform(0.7, 1.3)
bright_image = cv2.convertScaleAbs(image, alpha=brightness, beta=0)

# Contraste
contrast = random.uniform(0.8, 1.2)
contrasted = cv2.convertScaleAbs(image, alpha=contrast, beta=128*(1-contrast))

# Saturaci√≥n (HSV)
hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
hsv[:, :, 1] = hsv[:, :, 1] * random.uniform(0.7, 1.3)
saturated = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
```

**Transformaciones de Ruido:**

```python
# Ruido Gaussiano
noise = np.random.normal(0, 25, image.shape).astype(np.uint8)
noisy_image = cv2.add(image, noise)

# Desenfoque
blurred = cv2.GaussianBlur(image, (5, 5), 0)
```

**Configuraci√≥n de Aumentaci√≥n en YOLO:**

```python
# training_config.yaml
augmentation:
  hsv_h: 0.015      # Hue augmentation
  hsv_s: 0.7        # Saturation augmentation
  hsv_v: 0.4        # Value augmentation
  degrees: 0.0      # Rotation (+/- deg)
  translate: 0.1    # Translation (+/- fraction)
  scale: 0.5        # Scale (+/- gain)
  shear: 0.0        # Shear (+/- deg)
  perspective: 0.0  # Perspective (+/- fraction)
  flipud: 0.0       # Flip up-down (probability)
  fliplr: 0.5       # Flip left-right (probability)
  mosaic: 1.0       # Mosaic augmentation (probability)
  mixup: 0.0        # Mixup augmentation (probability)
```

**Beneficios del Aumento de Datos:**
- ‚úÖ Mayor tama√±o efectivo del dataset
- ‚úÖ Mejor generalizaci√≥n del modelo
- ‚úÖ Reducci√≥n de sobreajuste
- ‚úÖ Robustez a variaciones de iluminaci√≥n
- ‚úÖ Invarianza a transformaciones geom√©tricas

---

*Contin√∫a en [02_ARQUITECTURA_Y_ENTRENAMIENTO.md](./02_ARQUITECTURA_Y_ENTRENAMIENTO.md)*
